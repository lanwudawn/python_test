import streamlit as st
import cv2
import tempfile
import os
from pathlib import Path
import time
import numpy as np
from PIL import Image
import pandas as pd
from datetime import datetime

from ..models.yolo_model import YOLOModel
from ..utils.config_loader import load_config
from ..reports.visualization import DetectionVisualizer
from ..reports.metrics import DetectionMetrics

import altair as alt

@st.cache_resource
def load_cached_model(config):
    """
    ä½¿ç”¨ cache_resource ç¼“å­˜æ¨¡å‹å®ä¾‹ã€‚
    Streamlit ä¼šæ£€æµ‹ config æ˜¯å¦å˜åŒ–ï¼Œåªæœ‰å˜åŒ–æ—¶æ‰ä¼šé‡æ–°åŠ è½½ã€‚
    """
    print("Loading model...")  # è°ƒè¯•ç”¨ï¼Œä½ ä¼šå‘ç°å®ƒåªæ‰“å°ä¸€æ¬¡
    return YOLOModel(config)


class StreamlitApp:
    def __init__(self):
        self.setup_page_config()
        self.config = load_config()
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¸å†åœ¨ __init__ é‡Œå¼ºè¡ŒåŠ è½½æ¨¡å‹ï¼Œè€Œæ˜¯æŒ‰éœ€åŠ è½½
        self.apply_custom_css()
        self.initialize_session_state()

    def get_model(self):
        """è·å–ç¼“å­˜çš„æ¨¡å‹çš„è¾…åŠ©æ–¹æ³•"""
        return load_cached_model(self.config['model'])

    def process_image(self, image_file):
        """å¤„ç†å•å¼ å›¾ç‰‡"""
        # ä½¿ç”¨ç¼“å­˜åŠ è½½ï¼Œéå¸¸å¿«
        model = self.get_model()
        
        image = Image.open(image_file)
        image = np.array(image)
        
        # è¿™é‡Œçš„ predict å·²ç»æ˜¯ä¼˜åŒ–è¿‡çš„æ–¹æ³•
        detections = model.predict(image)

        visualizer = DetectionVisualizer(model.class_names) # ç¡®ä¿ä¼ å…¥ class_names
        
        return visualizer.draw_detections(image, detections)



    def setup_page_config(self):
        """è®¾ç½®é¡µé¢é…ç½®"""
        st.set_page_config(
            page_title="AIçš„ç›®æ ‡æ£€æµ‹ç³»ç»Ÿ",
            page_icon="ğŸ¯",
            layout="wide",
            initial_sidebar_state="expanded"
        )

    def apply_custom_css(self):
        """åº”ç”¨è‡ªå®šä¹‰CSSæ ·å¼"""
        st.markdown("""
        <style>
        /* ä¸»é¢˜é¢œè‰² */
        :root {
            --primary-bg: #FEFCE8;
            --secondary-bg: #FFFFFF;
            --accent-color: #F59E0B;
            --text-color: #1F2937;
            --card-bg: #FEF3C7;
        }
        
        /* å…¨å±€æ ·å¼ */
        .stApp {
            background: linear-gradient(135deg, var(--primary-bg) 0%, var(--secondary-bg) 100%);
            color: var(--text-color);
        }
        
        /* ä¾§è¾¹æ æ ·å¼ */
        .css-1d391kg {
            background-color: var(--card-bg);
        }
        
        /* å¡ç‰‡æ ·å¼ */
        .card {
            background: var(--card-bg);
            border-radius: 10px;
            padding: 1.5rem;
            border: 1px solid rgba(255, 255, 255, 0.1);
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            margin-bottom: 1rem;
            backdrop-filter: blur(10px);
        }
        
        /* æ ‡é¢˜æ ·å¼ */
        h1 {
            background: linear-gradient(90deg, #1E88E5, #64B5F6);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            font-weight: 700;
            font-size: 2.5rem;
            margin-bottom: 2rem;
        }
        
        h2, h3 {
            color: var(--text-color);
            font-weight: 500;
        }
        
        /* æŒ‰é’®æ ·å¼ */
        .stButton>button {
            background: linear-gradient(90deg, #1E88E5, #64B5F6);
            color: white;
            border: none;
            padding: 0.5rem 2rem;
            border-radius: 5px;
            font-weight: 500;
            transition: all 0.3s ease;
        }
        
        .stButton>button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(30, 136, 229, 0.3);
        }
        
        /* æŒ‡æ ‡å¡ç‰‡æ ·å¼ */
        .metric-card {
            background: var(--card-bg);
            border-radius: 10px;
            padding: 1.5rem;
            text-align: center;
            border: 1px solid rgba(255, 255, 255, 0.1);
            transition: transform 0.3s ease;
        }
        
        .metric-card:hover {
            transform: translateY(-5px);
        }
        
        .metric-value {
            font-size: 2.5rem;
            font-weight: 700;
            color: #1E88E5;
            margin: 0.5rem 0;
        }
        
        .metric-label {
            color: var(--text-color);
            font-size: 1rem;
            opacity: 0.8;
        }
        
        /* è¿›åº¦æ¡æ ·å¼ */
        .stProgress > div > div > div {
            background: linear-gradient(90deg, #1E88E5, #64B5F6);
        }
        
        /* é€‰æ‹©å™¨æ ·å¼ */
        .stSelectbox > div > div {
            background-color: var(--card-bg);
            border: 1px solid rgba(255, 255, 255, 0.1);
        }
        
        /* å›¾è¡¨æ ·å¼ */
        .stPlot {
            background: var(--card-bg);
            border-radius: 10px;
            padding: 1rem;
        }
        
        /* åŠ¨ç”»æ•ˆæœ */
        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(30, 136, 229, 0.4); }
            70% { box-shadow: 0 0 0 10px rgba(30, 136, 229, 0); }
            100% { box-shadow: 0 0 0 0 rgba(30, 136, 229, 0); }
        }
        
        .detection-active {
            animation: pulse 2s infinite;
        }
        
        /* ä¸Šä¼ åŒºåŸŸæ ·å¼ */
        .uploadfile {
            border: 2px dashed rgba(255, 255, 255, 0.2);
            border-radius: 10px;
            padding: 2rem;
            text-align: center;
            transition: all 0.3s ease;
        }
        
        .uploadfile:hover {
            border-color: var(--accent-color);
        }
        
        /* è¡¨æ ¼æ ·å¼ */
        .dataframe {
            background: var(--card-bg);
            border-radius: 10px;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }
        </style>
        """, unsafe_allow_html=True)

    def initialize_session_state(self):
        """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
        if 'model' not in st.session_state:
            st.session_state.model = None
        if 'metrics' not in st.session_state:
            st.session_state.metrics = DetectionMetrics()
        if 'running' not in st.session_state:
            st.session_state.running = False

    def run(self):
        """è¿è¡ŒStreamlitåº”ç”¨"""
        self.render_header()
        
        # åˆ›å»ºæ ‡ç­¾é¡µ
        tabs = st.tabs([
            "ğŸ¥ è§†é¢‘ç›®æ ‡æ£€æµ‹",
            "ğŸ–¼ï¸ å›¾ç‰‡åˆ†æ",
            "ğŸ“Š åˆ†æå¤§å±"
        ])
        
        with tabs[0]:
            self.render_realtime_detection()
        with tabs[1]:
            self.render_image_detection()
        with tabs[2]:
            self.render_analytics()

    def render_header(self):
        """æ¸²æŸ“é¡µé¢å¤´éƒ¨"""
        st.markdown("""
        <div style="text-align: center; padding: 2rem 0;">
            <h1>AIçš„ç›®æ ‡æ£€æµ‹</h1>
            <p style="color: #64B5F6; font-size: 1.2rem;">
                ç›®æ ‡æ£€æµ‹åŠåˆ†æ
            </p>
        </div>
        """, unsafe_allow_html=True)

    def render_metric_card(self, title, value, icon):
        """æ¸²æŸ“æŒ‡æ ‡å¡ç‰‡"""
        st.markdown(f"""
        <div class="metric-card">
            <div style="font-size: 2rem; color: #64B5F6; margin-bottom: 0.5rem;">
                {icon}
            </div>
            <div class="metric-value">{value}</div>
            <div class="metric-label">{title}</div>
        </div>
        """, unsafe_allow_html=True)

    def render_realtime_detection(self):
        """æ¸²æŸ“å®æ—¶æ£€æµ‹é¡µé¢"""
        col1, col2 = st.columns([6, 4])
        
        with col1:
            st.markdown('<div class="card">', unsafe_allow_html=True)
            video_placeholder = st.empty()
            video_placeholder.write("å¯¼å…¥æ–‡ä»¶")
            # æ·»åŠ çŠ¶æ€æŒ‡ç¤ºå™¨
            if st.session_state.running:
                st.markdown("""
                    <div style="text-align: center; color: #1E88E5;">
                        ğŸ”´ æ­£åœ¨å½•åˆ¶
                    </div>
                """, unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)

        with col2:
            st.markdown('<div class="card">', unsafe_allow_html=True)
            st.markdown("### æ§åˆ¶ç•Œé¢")
            source = st.radio(
                "Select Input Source",
                ["ğŸ“¹ æ‘„åƒå¤´", "ğŸ“ è§†é¢‘æ–‡ä»¶"],
                key="source_select"
            )

            if source == "ğŸ“¹ æ‘„åƒå¤´":
                camera_id = st.selectbox("é€‰æ‹©é€šé“", [0, 1, 2])
                self.run_camera_detection(camera_id, video_placeholder)
            else:
                st.markdown('<div class="uploadfile">', unsafe_allow_html=True)
                video_file = st.file_uploader(
                    "æ‹–æ‹½æ–‡ä»¶åˆ°æ­¤",
                    type=['mp4', 'avi', 'mov']
                )
                st.markdown('</div>', unsafe_allow_html=True)

                if video_file:
                    self.run_video_detection(video_file, video_placeholder)

            st.markdown('</div>', unsafe_allow_html=True)

    def render_image_detection(self):
        """æ¸²æŸ“å›¾ç‰‡æ£€æµ‹é¡µé¢"""
        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown("### å›¾ç‰‡åˆ†æ")
        
        upload_col, preview_col = st.columns([3,7])
        
        with upload_col:
            st.markdown('<div class="uploadfile">', unsafe_allow_html=True)
            uploaded_file = st.file_uploader(
                "æ‹–æ‹½æ–‡ä»¶åˆ°æ­¤",
                type=['jpg', 'jpeg', 'png']
            )
            st.markdown('</div>', unsafe_allow_html=True)
            
        if uploaded_file:
            image = Image.open(uploaded_file)
            preview_col.image(image, caption="Preview", use_container_width=True)
            
            if st.button("ğŸ” åˆ†ææ–‡ä»¶"):
                with st.spinner("åˆ†æä¸­..."):
                    result_image = self.process_image(uploaded_file)
                    st.image(result_image, caption="Detection Result")
        
        st.markdown('</div>', unsafe_allow_html=True)

    def render_analytics(self):
        """æ¸²æŸ“åˆ†æé¡µé¢ï¼ˆä½¿ç”¨ Altair ä¼˜åŒ–å›¾è¡¨ï¼‰"""
        if 'metrics' not in st.session_state or not st.session_state.metrics:
            st.info("æš‚æ— æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œæ£€æµ‹ã€‚")
            return

        metrics = st.session_state.metrics.get_summary()
        
        # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡å¡ç‰‡
        st.markdown('<div class="card">', unsafe_allow_html=True)
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æ€»è®¡å¸§æ•°", metrics['total_frames'])
        with col2:
            # ğŸŸ¢ ä¿®æ­£ï¼šä½¿ç”¨ 'average_fps' è€Œä¸æ˜¯ 'fps'
            st.metric("å¹³å‡å¸§ç‡", f"{metrics['average_fps']:.1f} FPS")
        with col3:
            st.metric("æ£€æµ‹ç›®æ ‡", metrics['total_detections'])
        st.markdown('</div>', unsafe_allow_html=True)
        
        # --- å›¾è¡¨ä¼˜åŒ–éƒ¨åˆ† ---
        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown("### ğŸ“Š ç›®æ ‡åˆ†ç±»ç»Ÿè®¡")
        
        counts = metrics['class_distribution']
        if counts:
            model = self.get_model()
            class_names = model.class_names if model else []
            
            # æ•°æ®è½¬æ¢
            named_counts = []
            for cls_id, count in counts.items():
                if class_names and 0 <= cls_id < len(class_names):
                    name = class_names[cls_id]
                else:
                    name = f"Class {cls_id}"
                named_counts.append({"ç±»åˆ«": name, "æ•°é‡": count})
            
            # åˆ›å»º DataFrame
            chart_data = pd.DataFrame(named_counts)
            
            if not chart_data.empty:
                # ä½¿ç”¨ Altair æ„å»ºå›¾è¡¨
                bars = alt.Chart(chart_data).mark_bar().encode(
                    x=alt.X('æ•°é‡', title='æ£€æµ‹æ•°é‡'),
                    y=alt.Y('ç±»åˆ«', sort='-x', title=''),
                    color=alt.Color('ç±»åˆ«', legend=None),
                    tooltip=['ç±»åˆ«', 'æ•°é‡']
                )
                
                text = bars.mark_text(
                    align='left',
                    baseline='middle',
                    dx=3
                ).encode(
                    text='æ•°é‡'
                )
                
                final_chart = (bars + text).properties(height=300)
                st.altair_chart(final_chart, use_container_width=True)
            else:
                 st.info("æš‚æ— æœ‰æ•ˆåˆ†ç±»æ•°æ®")
        else:
            st.info("æš‚æ— åˆ†ç±»ç»Ÿè®¡æ•°æ®")
            
        st.markdown('</div>', unsafe_allow_html=True)


    def process_image(self, image_file):
        """å¤„ç†å•å¼ å›¾ç‰‡"""
        if st.session_state.model is None:
            st.session_state.model = YOLOModel(self.config['model'])
        
        image = Image.open(image_file)
        image = np.array(image)
        
        detections = st.session_state.model.predict(image)
        visualizer = DetectionVisualizer()
        
        return visualizer.draw_detections(image, detections)

    def run_camera_detection(self, camera_id, placeholder):
        """è¿è¡Œæ‘„åƒå¤´æ£€æµ‹"""
        cap = cv2.VideoCapture(camera_id)
        
        model = self.get_model()
        
        visualizer = DetectionVisualizer(model.class_names)
        # åˆ›å»ºä¸¤åˆ—å¸ƒå±€ç”¨äºå¼€å§‹å’Œåœæ­¢æŒ‰é’®
        col1, col2 = st.columns(2)
        
        with col1:
            start_button = st.button("â–¶ï¸ å¼€å§‹")
        with col2:
            stop_button = st.button("â¹ï¸ ç»“æŸ")
            
        if start_button:
            st.session_state.running = True
            st.session_state.metrics.reset()

        if stop_button:
            st.session_state.running = False
            
        try:
            while st.session_state.running:
                start_time = time.time()

                ret, frame = cap.read()
                if not ret:
                    st.warning("æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢")
                    break
                
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
                detections = model.predict(frame)

                process_time = time.time() - start_time
                if st.session_state.metrics:
                    st.session_state.metrics.update(detections, process_time)

                if detections is not None:
                    frame = visualizer.draw_detections(frame, detections)
                
                placeholder.image(frame)
                
        finally:
            cap.release()
            st.session_state.running = False

    def run_video_detection(self, video_file, placeholder):
        """è¿è¡Œè§†é¢‘æ–‡ä»¶æ£€æµ‹"""
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(video_file.read())
        
        cap = cv2.VideoCapture(tfile.name)
        
        model = self.get_model()
        
        visualizer = DetectionVisualizer(model.class_names)

        if st.session_state.model is None:
            st.session_state.model = YOLOModel(self.config['model'])
    

        # åˆ›å»ºä¸¤åˆ—å¸ƒå±€ç”¨äºå¼€å§‹å’Œåœæ­¢æŒ‰é’®
        col1, col2 = st.columns(2)
        
        with col1:
            start_button = st.button("â–¶ï¸ å¼€å§‹")
        with col2:
            stop_button = st.button("â¹ï¸ ç»“æŸ")
            
        if start_button:
            st.session_state.running = True
            st.session_state.metrics.reset()

        if stop_button:
            st.session_state.running = False
            
        try:
            while st.session_state.running:

                start_time = time.time()

                ret, frame = cap.read()
                if not ret:
                    break
                
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                detections = st.session_state.model.predict(frame)
                
                process_time = time.time() - start_time
                if st.session_state.metrics:
                    st.session_state.metrics.update(detections, process_time)

                if detections is not None:
                    frame = visualizer.draw_detections(frame, detections)
                
                placeholder.image(frame)
                
        finally:
            cap.release()
            os.unlink(tfile.name)
            st.session_state.running = False 